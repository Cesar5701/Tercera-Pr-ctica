{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRI Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones de bibliotecas y módulos necesarios\n",
    "import os\n",
    "import subprocess\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente parte, donde dice start_url cambiala por la que gustes. Creará una carpeta llamada paginas en caso de que no exista y si existe dentro de usa carpeta creará otro subdirectorio con la fecha y hora de hoy para ordenarlos y seprarlos, en caso de que solo necesites leer los de una carpeta y ya no necesites scrapear o descargar nuevos archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el módulo subprocess para ejecutar comandos del sistema\n",
    "import subprocess\n",
    "\n",
    "# Define un comando para ejecutar un spider de Scrapy, especificando la URL de inicio y la profundidad\n",
    "comando = [\"scrapy\", \"crawl\", \"sp_ward\", \"-a\", \"start_url=https://es.wikipedia.org/wiki/Puedo_prometer_y_prometo\", \"-a\", \"depth=2\"]\n",
    "# Ejecuta el comando en un directorio específico\n",
    "subprocess.run(comando, cwd=\"../Tercera Práctica/SC_WARD/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para listar subcarpetas en un directorio dado\n",
    "def listar_subcarpetas(ruta):\n",
    "    # Utiliza list comprehension para crear una lista de subcarpetas\n",
    "    subcarpetas = [carpeta for carpeta in os.listdir(ruta) if os.path.isdir(os.path.join(ruta, carpeta))]\n",
    "    return subcarpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para leer archivos de texto de un directorio\n",
    "def leer_archivos(directorio):\n",
    "    textos = []  # Lista para almacenar los textos leídos\n",
    "    # Itera sobre los archivos en el directorio\n",
    "    for archivo in os.listdir(directorio):\n",
    "        # Chequea si el archivo es un archivo de texto\n",
    "        if archivo.endswith(\".txt\"):\n",
    "            # Abre y lee el archivo, añadiendo su contenido a la lista de textos\n",
    "            with open(os.path.join(directorio, archivo), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                textos.append(f.read())\n",
    "    return textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para procesar texto HTML y obtener palabras limpias\n",
    "def procesar_texto(html):\n",
    "    # Utiliza BeautifulSoup para eliminar etiquetas HTML y obtener texto plano\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    texto = soup.get_text()\n",
    "\n",
    "    # Tokeniza el texto y normaliza a minúsculas, eliminando acentos\n",
    "    tokens = word_tokenize(texto, language='spanish')\n",
    "    palabras = [eliminar_acentos(palabra.lower()) for palabra in tokens if palabra.isalpha()]\n",
    "\n",
    "    # Elimina stopwords en español y palabras de longitud menor a 3\n",
    "    palabras_sin_stopwords = [palabra for palabra in palabras if palabra not in stopwords.words('spanish') and len(palabra) > 2]\n",
    "    return palabras_sin_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para eliminar acentos de las palabras\n",
    "def eliminar_acentos(palabra):\n",
    "    return unidecode.unidecode(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para crear un diccionario de términos a partir de una lista de textos\n",
    "def crear_diccionario(textos):\n",
    "    diccionario = set()  # Utiliza un conjunto para almacenar términos únicos\n",
    "    # Actualiza el diccionario con palabras de cada texto\n",
    "    for texto in textos:\n",
    "        diccionario.update(texto)\n",
    "    return diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para guardar el diccionario en un archivo\n",
    "def guardar_diccionario(diccionario, nombre_archivo):\n",
    "    with open(nombre_archivo, 'w', encoding='utf-8') as f:\n",
    "        # Escribe cada término del diccionario en el archivo, ordenados alfabéticamente\n",
    "        for termino in sorted(diccionario):\n",
    "            f.write(termino + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interfaz para elegir una subcarpeta de un directorio de páginas scrapeadas\n",
    "ruta_paginas = 'SC_WARD/paginas'\n",
    "subcarpetas = listar_subcarpetas(ruta_paginas)\n",
    "print(\"Subcarpetas disponibles:\")\n",
    "for idx, carpeta in enumerate(subcarpetas):\n",
    "    print(f\"{idx + 1}. {carpeta}\")\n",
    "\n",
    "# Permite al usuario seleccionar una subcarpeta y lee los archivos de esa carpeta\n",
    "eleccion = int(input(\"Seleccione el número de la subcarpeta: \"))\n",
    "ruta_seleccionada = os.path.join(ruta_paginas, subcarpetas[eleccion - 1])\n",
    "textos_scrapeados = leer_archivos(ruta_seleccionada)\n",
    "\n",
    "# Procesa los textos scrapeados y crea un diccionario de términos\n",
    "textos_procesados = [procesar_texto(html) for html in textos_scrapeados]\n",
    "diccionario = crear_diccionario(textos_procesados)\n",
    "\n",
    "# Guarda el diccionario en un archivo\n",
    "guardar_diccionario(diccionario, 'diccionario.txt')\n",
    "print(\"Diccionario guardado en 'diccionario.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para crear una matriz booleana a partir de los textos y el diccionario\n",
    "def crear_matriz(textos, diccionario, nombres_archivos):\n",
    "    matriz = []  # Lista para almacenar la matriz\n",
    "    diccionario_lista = sorted(list(diccionario))  # Convierte el diccionario a una lista ordenada\n",
    "    # Itera sobre cada texto y su nombre de archivo correspondiente\n",
    "    for texto, nombre_archivo in zip(textos, nombres_archivos):\n",
    "        # Crea una fila en la matriz con valores booleanos indicando la presencia de palabras del diccionario en el texto\n",
    "        fila = [palabra in texto for palabra in diccionario_lista]\n",
    "        matriz.append((nombre_archivo, fila))\n",
    "    return matriz, diccionario_lista\n",
    "\n",
    "# Define una función para guardar la matriz booleana en un archivo\n",
    "def guardar_matriz(matriz, diccionario_lista, nombre_archivo):\n",
    "    with open(nombre_archivo, 'w', encoding='utf-8') as f:\n",
    "        # Escribe el encabezado con los términos del diccionario\n",
    "        f.write('Archivo\\t' + '\\t'.join(diccionario_lista) + '\\n')\n",
    "        # Escribe cada fila de la matriz con el nombre del archivo y los valores booleanos\n",
    "        for nombre_archivo, fila in matriz:\n",
    "            f.write(nombre_archivo + '\\t' + '\\t'.join(['1' if val else '0' for val in fila]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene los nombres de los archivos y crea la matriz booleana\n",
    "nombres_archivos = [archivo for archivo in os.listdir(ruta_seleccionada) if archivo.endswith(\".txt\")]\n",
    "matriz, diccionario_lista = crear_matriz(textos_procesados, diccionario, nombres_archivos)\n",
    "\n",
    "# Guarda la matriz booleana en un archivo\n",
    "guardar_matriz(matriz, diccionario_lista, 'matriz.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite al usuario ingresar una consulta y la muestra\n",
    "consulta_q = input(\"Ingrese su consulta: \")\n",
    "print(consulta_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para procesar la consulta del usuario\n",
    "def procesar_consulta(consulta):\n",
    "    # Elimina HTML, si hay, y normaliza el texto\n",
    "    consulta_sin_html = BeautifulSoup(consulta, 'html.parser').get_text()\n",
    "    tokens = word_tokenize(consulta_sin_html, language='spanish')\n",
    "    palabras = [palabra.lower() for palabra in tokens if palabra.isalpha()]\n",
    "    # Elimina stopwords y aplica stemming\n",
    "    palabras_sin_stopwords = [palabra for palabra in palabras if palabra not in stopwords.words('spanish')]\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    consulta_stemmed = [stemmer.stem(palabra) for palabra in palabras_sin_stopwords]\n",
    "    return consulta_stemmed\n",
    "\n",
    "# Procesa la consulta ingresada por el usuario\n",
    "consulta_procesada = procesar_consulta(consulta_q)\n",
    "print(consulta_procesada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para vectorizar la consulta procesada\n",
    "def vectorizar_consulta(consulta, diccionario_lista):\n",
    "    # Crea un vector booleano para la consulta basado en el diccionario\n",
    "    return [palabra in consulta for palabra in diccionario_lista]\n",
    "\n",
    "# Vectoriza la consulta y la muestra\n",
    "vector_consulta = vectorizar_consulta(consulta_procesada, diccionario_lista)\n",
    "print(vector_consulta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa los nombres de archivo y los vectores booleanos de la matriz\n",
    "nombres_archivos = [fila[0] for fila in matriz]\n",
    "vectores_booleanos = [fila[1] for fila in matriz]\n",
    "\n",
    "# Convierte los vectores booleanos a un array de NumPy para manipulación matricial\n",
    "matriz_np = np.array(vectores_booleanos)\n",
    "\n",
    "# Convierte el vector de la consulta a un array de NumPy y lo añade a la matriz\n",
    "vector_consulta_np = np.array(vector_consulta)\n",
    "matriz_con_consulta = np.vstack([matriz_np, vector_consulta_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica el clustering aglomerativo usando el método de Ward\n",
    "modelo = AgglomerativeClustering(n_clusters=None, distance_threshold=0, linkage='ward')\n",
    "modelo = modelo.fit(matriz_con_consulta)\n",
    "\n",
    "# Genera y muestra un dendrograma para visualizar el clustering\n",
    "dendrograma = sch.dendrogram(sch.linkage(matriz_con_consulta, method='ward'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
